---
title: "Homework 5 R markdown"
author: "(your name here)"
date: '`r Sys.Date()`'
output:
  word_document:
    fig_height: 4
    fig_width: 4.5
  pdf_document:
    fig_height: 4
    fig_width: 4.5
  html_document:
    fig_height: 4
    fig_width: 4.5
---


```{r, setup, include=FALSE}
require(mosaic)   # Load additional packages here 

# Some customization.  You can alter or delete as desired (if you know what you are doing).
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

#### <span style="color:Blue">**Intellectual Property:**</span>  
These problems are the intellectual property of the instructors and may not be reproduced outside of this course.

#### <span style="color:Crimson">**Due Date:**</span>  


***  
***  

##########################################################################
## Problem 1: Identifying Methods
##########################################################################

<span style="color:DarkViolet">Using the data in the Trees.csv file, fit the response Volume on the remaining variables, find coefficient estimates for the model  
$Volume = \beta_0 + \beta_1 Girth + \beta_2 Height + \beta_3 GirthHeight + \beta_4 Girth2 +\beta_5 Girth2Height$  
using each of the following methods:  
1.  Multiple linear regression  
2.  Ridge Regression ($\alpha$  = 0), with $\lambda$ = 0.01, 0.02, …, 0.99, 1.00.  
3.  LASSO ($\alpha$ = 1), with $\lambda$ = 0.01, 0.02, …, 0.99, 1.00.  
4.  Elastic net, with $\alpha$  = 0.7 and $\lambda$ = 0.01, 0.02, …, 0.99, 1.00. </span>

```{r,echo=FALSE}
trees = read.csv("Trees.csv")
colnames(trees)
#multiple linear regression
origfit = lm(Volume ~ Girth + Height + GirthHeight + Girth2 + Girth2Height,data=trees)
summary(origfit)

#labels
x = model.matrix(Volume ~ Girth + Height + GirthHeight + Girth2 + Girth2Height,data=trees)[,c(-1)]
y = trees[,2]
n = dim(x)[1]
p = dim(x)[2]

#ridge regression
library(glmnet)  # may need to download package glmnet
lambdalist = (1:100)/100  # order large to small
#fit ridge regression - need alpha = 0
RRfit = glmnet(x, y, alpha = 0,lambda=lambdalist)
coef(RRfit,s=0.1)
#LASSO
LASSOfit = glmnet(x, y, alpha = 1,lambda=lambdalist)
coef(LASSOfit,s=0.1)
#Elastic net
ENETfit = glmnet(x, y, alpha = 0.7,lambda=lambdalist)
coef(ENETfit,s=0.1)
```

#####################################
### <span style="color:DarkViolet">Question 1</span> **<span style="color:Crimson">(1 point)</span>**:
#####################################

<span style="color:DarkViolet">Consider the fit of model 1., multiple linear regression. How many of the predictors are marginally significant (after fitting the other predictors)?</span>  

<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
->0,  
1,  
2,  
3,  
4

#####################################
### <span style="color:DarkViolet">Question 2</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">Provide an explanation for the answer to the previous question. </span>

There is likely multicolinearity happening. The features are highly correlated with each other.

<span style="color:green">**Text Answer**: </span>

#####################################
### <span style="color:DarkViolet">Question 3</span> **<span style="color:Crimson">( points)</span>**:
#####################################

<span style="color:DarkViolet">Which of the following methods could **NOT** have produced the below coefficients? Select all methods that apply.  
$\hat{\beta}_0$ = −5.90695, $\hat{\beta}_1$ = 0, $\hat{\beta}_2$ = 0, $\hat{\beta}_3$ = 0.01194, $\hat{\beta}_4$ = 0.03991, $\hat{\beta}_5$ = 0.00115</span>  

<span style="color:green">**Multiple SELECT Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  
->Multiple linear regression,  
->Ridge Regression,  
Elastic net,  
LASSO  

***

#####################################
### <span style="color:DarkViolet">Question 4-9</span> **<span style="color:Crimson">(6 points, 1 each)</span>**:
#####################################

<span style="color:DarkViolet">Input the values for the coefficients of the LASSO model fit with $\lambda$ = 0.1. Please use the values  
$\texttt{lambdalist = c((1:100)/100)}$  
for fitting with the glmnet() function.</span>  

<span style="color:DarkViolet">$\hat{\beta}_0$ = -1.714025816
$\hat{\beta}_1$ = 0  
$\hat{\beta}_2$ = 0.010552334 
$\hat{\beta}_3$ = 0.001864428 
$\hat{\beta}_4$ = 0 
$\hat{\beta}_5$ = 0.002035016</span>    

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
```{r,echo=FALSE}

```

***

#####################################
### <span style="color:DarkViolet">Question 10</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">The image shows a plot of the $CV_{(5)}$ values for the Ridge Regression, LASSO, and Elastic net models, plotted against the value of $\lambda$.  Which model is optimal?</span>

[See D2L Homework 5 for image, not able to include in code.]  

<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
Elastic net,  
Ridge Regression,  
Multiple linear regression,  
->LASSO



#####################################
### <span style="color:DarkViolet">Question 11</span> **<span style="color:Crimson">(1 point)</span>**:
#####################################

<span style="color:DarkViolet">The model you chose in the previous question is optimal with $\lambda \approx$</span>  

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  

lamda = .4


***
***

##########################################################################
## Problem 2:  Motivation for Penalized Regression
##########################################################################

<span style="color:DarkViolet">For the **College** data set from the **ISLR** package, we will work to predict *log.Enroll*, the natural log transformation of *Enroll*, the number of new students enrolled (per year) as a function of the other variables.  You may use the $\texttt{help(College)}$ command to learn more about the dataset. </span>


***

#####################################
### <span style="color:DarkViolet">Question 12</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">Each of the five variables *Enroll, Apps, Accept, F.Undergrad*, and *P.Undergrad* is related to the size of the college and has strongly right-skewed distribution.  Explain why the skewness makes sense, in terms of the variety of colleges covered in this dataset. </span>

Looking the histogram of Enroll, it is indeed right skewed. From the summary of the Enroll, the minimum enrolled is 35 and the maximum enrolled is 6392. The enrollment range is so large that this would likely make F.Undergrad, and P.Undergrad also skewed. Along with the total enrollment, the prestige of the college could also make Apps, and Accep right skewed.

<span style="color:green">**Text Answer**: </span>


#####################################
### <span style="color:DarkViolet">Question 13</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">To make linear relationships more reasonable, log transformation of these five variables work well. Define the new variables *log.Enroll, log.Apps, log.Accept, log.F.Undergrad*, and *log.P.Undergrad* as the (natural) log transformation of the corresponding variables.  Add these variables to the data frame.  Submit an appropriate plot for describing the distribution of the response, *log.Enroll*, to **Homework 5: Distribution of response** discussion. </span>

<span style="color:green">**Graph Answer**  </span>: 
  (post to discussion board on D2L)
```{r,echo=FALSE}
library(ISLR)
data("College")
help("College")

College$log.Enroll = log(College$Enroll)
College$log.Apps = log(College$Apps)
College$log.Accept = log(College$Accept)
College$log.F.Undergrad = log(College$F.Undergrad)
College$log.P.Undergrad = log(College$P.Undergrad)

hist(College$log.Enroll, xlab = "log of Enrollment", main = "Histogram of Log of Enrollment")


#correlation
x = model.matrix(log.Enroll~Expend+log.Accept+log.P.Undergrad+perc.alumni+Personal,data=College)
y = College[,"log.Enroll"]

#cor(x)
cor(x,y)
```


#####################################
### <span style="color:DarkViolet">Question 14</span> **<span style="color:Crimson">(1 point)</span>**:
#####################################

<span style="color:DarkViolet">Which of the following predictors is most highly correlated with the response *log.Enroll*</span>?

<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
Expend,  
->log.Accept,  
log.P.Undergrad,  
perc.alumni,  
Personal

 


#####################################
### <span style="color:DarkViolet">Question 15</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">Provide a reason that the predictor you chose in the previous question makes sense, based on the description of the data. </span>

Accept is the number of students accepted. It would be expected that this would be highly correlated with enrollment.

<span style="color:green">**Text Answer**: </span>



#####################################
### <span style="color:DarkViolet">Question 16</span> **<span style="color:Crimson">(3 points)</span>**:
#####################################

<span style="color:DarkViolet">Describe features of this data set that support using a penalized regression model (versus a basic multiple linear regression model). </span>

<span style="color:green">**Text Answer**: </span>
Many of the variables are highly correlated with each other.

***
***

##########################################################################
## Problem 3:  Applying Methods
##########################################################################

<span style="color:DarkViolet">Using the data **College** data set from the **ISLR** package, with the new variables as defined in Problem 2, fit the response *log.Enroll* on the remaining variables:  *Private, Top10perc, Top25perc, Outstate, Room.Board, Books, Personal, PhD, Terminal, S.F.Ratio, perc.alumni, Expend, Grad.Rate, log.Apps, log.Accept, log.F.Undergrad, log.P.Undergrad*.  </span>

***

<span style="color:DarkViolet">For the following questions 17-20,  fit the LASSO ($\alpha$ = 1) model and find coefficients for $\lambda$ = 0.001, 0.002, …, 0.999, 1.000.  Determine how many coefficients are non-zero, **excluding the intercept**.</span>

```{r echo=FALSE, eval=FALSE}
model = log.Enroll ~ Private + Top10perc + Top25perc + Outstate + Room.Board + Books + Personal + PhD + Terminal + S.F.Ratio + perc.alumni + Expend + Grad.Rate + log.Apps + log.Accept + log.F.Undergrad + log.P.Undergrad

lambdalist = (1:1000)/1000  # order large to small
#fit ridge regression - need alpha = 0
#RRfit = glmnet(x, y, alpha = 0,lambda=lambdalist)
#coef(RRfit,s=0.1)
#LASSO

x = model.matrix(model,data=College)
x
y = College[,"log.Enroll"]

LASSOfit = glmnet(x, y, alpha = 1,lambda=lambdalist)
coef(LASSOfit,s=0.02)
#Elastic net
#ENETfit = glmnet(x, y, alpha = 0.7,lambda=lambdalist)
#coef(ENETfit,s=0.1)
```

#####################################
#### <span style="color:DarkViolet">Question 17-20</span> **<span style="color:Crimson">(4 points, 1 each)</span>**:
#####################################

17.  For the LASSO model with $\lambda$ = 0.02, how many coefficients are non-zero?  
<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
1,  
2,  
3,  
4,  
5

18.  For the LASSO model with $\lambda$ = 0.03, how many coefficients are non-zero?  
<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
1,  
2,  
3,  
4,  
5

19.  For the LASSO model with $\lambda$ = 0.05, how many coefficients are non-zero?  
<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
1,  
2,  
3,  
4,  
5

20.  For the LASSO model with $\lambda$ = 0.8, how many coefficients are non-zero?  
<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
1,  
2,  
3,  
4,  
5



#####################################
#### <span style="color:DarkViolet">Question 21</span> **<span style="color:Crimson">(4 points)</span>**:
#####################################
<span style="color:DarkViolet">Which variable(s) appear to be the most useful for predicting *log.Enroll* with the LASSO model? Select all that apply.</span>

<span style="color:green">**Multiple SELECT Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  
Private,  
Top10perc,  
Top25perc,  
Outstate,  
Room.Board,  
Books,  
Personal,  
PhD,  
Terminal,  
S.F.Ratio,  
perc.alumni,  
Expend,  
Grad.Rate,  
log.Apps,  
log.Accept,  
log.F.Undergrad,  
log.P.Undergrad

***

<span style="color:DarkViolet">For the following questions, use the Elastic net model, with$\alpha$ = 0.75 and $\lambda$  = 0.001, 0.002, …, 0.999, 1.000.</span>



#####################################
### <span style="color:DarkViolet">Question 22</span> **<span style="color:Crimson">(3 points)</span>**:
#####################################


<span style="color:DarkViolet">Using set.seed(5), make groups for 10-fold cross-validation:  
$\texttt{groups = c(rep(1:10,77),(1:7))}$  
$\texttt{set.seed(5)  }$  
$\texttt{cvgroups = sample(groups,777)}$  
Use the $\texttt{cv.glmnet}$ command along with these cross-validation groups to perform crossvalidation,
with $CV_{(10)}$ contained in the value cvm of the output. For the Elastic net model
with $\alpha$ = 0.75, make a plot of $CV_{(10)}$ vs $\lambda$ and submit your plot to **Homework 5: Elastic net model plot**.
</span>

<span style="color:green">**Graph Answer**</span>: 
  (post to discussion board on D2L)
```{r,echo=FALSE}
```

#####################################
### <span style="color:DarkViolet">Question 23</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">For the Elastic net model with $\alpha$ = 0.75, what is the value of $\lambda$ that minimizes $CV_{(10)}$?</span>

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
```{r,echo=FALSE}
```


#####################################
### <span style="color:DarkViolet">Question 24</span> **<span style="color:Crimson">(3 points)</span>**:
#####################################

<span style="color:DarkViolet">Enter your R code below for computing the $CV_{(10)}$ measure for the Elastic net model with $\alpha$ = 0.75. </span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
```
