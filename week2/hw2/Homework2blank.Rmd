---
title: "Homework 2 R markdown"
author: "(your name here)"
date: '`r Sys.Date()`'
output:
  word_document:
    fig_height: 4
    fig_width: 4.5
  pdf_document:
    fig_height: 4
    fig_width: 4.5
  html_document:
    fig_height: 4
    fig_width: 4.5
---


```{r, setup, include=FALSE}
require(mosaic)   # Load additional packages here 

# Some customization.  You can alter or delete as desired (if you know what you are doing).
trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

#### <span style="color:Blue">**Intellectual Property:**</span>  
These problems are the intellectual property of the instructors and may not be reproduced outside of this course.

#### <span style="color:Crimson">**Due Date:**</span>  


***  

##########################################################################
## <span style="color:DarkViolet">Problem 1:  Model Assessment  </span>
##########################################################################

<span style="color:DarkViolet">This problem practices application of proper model assessment techniques, with a multiple linear regression model.</span>

<span style="color:DarkViolet">Download the data set *Trees.csv* [from Lesson 2 on D2L] and read it into R.  Reference with description of the *original* measurements may be found at: </span> https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/trees.html

```{r echo=FALSE}

```

<span style="color:DarkViolet">The general goal for this dataset is to predict Volume based on Girth and Height.  We will be fitting a predictive model using multiple linear regression.  The model is given below:
$Volume = \beta_0+\beta_1\cdot Girth +\beta_2\cdot Height+\beta_3\cdot Girth\cdot Height+\beta_4 \cdot Girth^2+\beta_5\cdot Girth^2\cdot Height$  
Note that there are five predictors, some of which are transformations of the original two variables Girth and Height, for predicting the value of the response variable Volume.</span>

### <span style="color:DarkViolet">Question 1</span> **<span style="color:Crimson">(3 points)</span>**
<span style="color:DarkViolet">Why is *Volume* the most reasonable response variable?  *Include real-world reasons (eg. physical practicalities) in your discussion.*</span>



<span style="color:green">**Text Answer**: According to the description of the data, the diameter in inches was mislabeled as girth. From geometry, the volume of a cylinder is a function of diamter and height, so it makes sense to have Volume as the response variable. </span>

***


### <span style="color:DarkViolet">Questions 2-7</span> **<span style="color:Crimson">(6 points, 1 each)</span>**
<span style="color:DarkViolet">Use multiple linear regression to find coefficient estimates:
</span>



```{r}
trees = read.csv("C:/Users/irgepi/source/repos/ds740_datamining/week2/hw2/Trees.csv")
#colnames(trees)
tree_volume_model = (Volume ~ Girth + Height + GirthHeight + Girth2 + Girth2Height)
tree_volume_fit = lm(tree_volume_model,data=trees)
summary(tree_volume_fit)
```

<span style="color:green">**Numeric Answer**  </span>  
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
$\beta_0 =$ 48.914179  
$\beta_1 =$ -8.228180   
$\beta_2 =$ -0.616152  
$\beta_3 =$ 0.103075 
$\beta_4 =$ 0.311160  
$\beta_5 =$ -0.001764  

### <span style="color:DarkViolet">Question 8</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">How many of these predictor variables are significant?</span>

<span style="color:green">**Multiple Choice Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**: 
    
0


*** 


<span style="color:DarkViolet">We now assess how useful the fitted model is, via k-fold cross-validation.</span>

### <span style="color:DarkViolet">Question 9</span> **<span style="color:Crimson">(1 point)</span>**
<span style="color:DarkViolet">In order to perform 5-fold cross-validation, how many separate models must be fit?</span>


<span style="color:green">**Multiple Choice Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**: 

1




### <span style="color:DarkViolet">Question 10</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Starting with:</span>

$\texttt{groups = c(rep(1:5,6),1)}$

<span style="color:DarkViolet">Set R’s seed to 2 (for Homework 2) and define cvgroups (random groups for the cross-validation) using the sample() function.  
Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 10
k=5
groups = c(rep(1:k,6),1)
set.seed(2)
cvgroups = sample(groups,31)  #orders randomly, with seed (2) to determine starting point
# Questions 11-12
allpredictedCV = rep(0,31)

for (i in 1:k)  {
  groupi = (cvgroups == i)
  lmfitCV = lm(formula = tree_volume_model,data=trees,subset=!groupi)
  allpredictedCV[groupi] = predict.lm(lmfitCV,trees[groupi,])
}
allpredictedCV[1]
allpredictedCV[2]

CV5 = sum((allpredictedCV-trees$Volume)^2)/31
CV5
```


### <span style="color:DarkViolet">Question 11</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Use the 5-fold CV method to assess the model fit. Provide the predicted y-value for the **first** observation: </span>


<span style="color:green">**Numeric Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:


### <span style="color:DarkViolet">Question 12</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Use the 5-fold CV method to assess the model fit. Provide the predicted y-value for the **second** observation: </span>


<span style="color:green">**Numeric Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:

***


### <span style="color:DarkViolet">Question 13</span> **<span style="color:Crimson">(4 points)</span>**

<span style="color:DarkViolet">Calculate and report the $CV_{(5)}$ based on the 5-fold cross-validation: </span>


```{r}
# Question 13
CV5 = sum((allpredictedCV-trees$Volume)^2)/31
CV5
```

<span style="color:green">**Numeric Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:



### <span style="color:DarkViolet">Question 14</span> **<span style="color:Crimson">(1 point)</span>**
<span style="color:DarkViolet">The MSE computed with the book’s formula is 5.70.  Note that this method assesses the model with the same data used to fit the model.  How does this compare to the value of $CV_{(5)}$ from the previous question? </span>

<span style="color:green">**Multiple Choice Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of 

A) 	The MSE value is **greater**.

-> B) 	The MSE value is **less**.

C) 	The two values are about the **same**.



### <span style="color:DarkViolet">Question 15</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Is the MSE of 5.70 accurate?  **Explain why or why not.** </span>

The MSE is not accurate. It is a calculation of the error based on an overfit of the data.

<span style="color:green">**Text Answer**: </span>


### <span style="color:DarkViolet">Question 16</span> **<span style="color:Crimson">(3 points)</span>**
<span style="color:DarkViolet">Enter your R code for computing the $CV_{(5)}$ measure below.</span>

<span style="color:green">**Code Answer**: </span>
```{r echo=TRUE}
```


***  



**Bootstrapping**

<span style="color:DarkViolet"> We will now use the bootstrap to estimate variability of the coefficients.</span>

### <span style="color:DarkViolet">Question 17</span> **<span style="color:Crimson">(4 points)</span>**:

<span style="color:DarkViolet"> Program a function, making use of lm() to fit the linear regression model, that outputs the six coefficient estimates.  Set R’s seed to 2, and then use $\texttt{boot()}$ to produce R = 1000 bootstrap estimates for each of $\beta_0$, $\beta_1$, $\beta_2$, $\beta_3$, $\beta_4$, and $\beta_5$.  
Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r echo=TRUE}
library(boot)  #need to install package
	#define functions that output coefficients (parameters to be estimated)
beta.fn = function(inputdata,index) {
  lmfitboot = lm(formula = tree_volume_model,data=inputdata[index,])
  return(lmfitboot$coef)
}

	#run the boot function to simulate re-samples (with replacement)
	#and obtain the coefficients for each re-sample
	#partial model bootstrap
set.seed(2)
bootoutput = boot(trees,beta.fn,R=1000)
print(bootoutput)

# Question 17 

# Question 18

# Question 19

# Question 20

# Question 21

# Question 22

# Question 23
```


### <span style="color:DarkViolet">Questions 18-23</span> **<span style="color:Crimson">(6 points, 1 each)</span>**:

<span style="color:DarkViolet">Use your bootstrap estimates to estimate the standard error, $SE(\beta_i)$, for each of i = 0, 1, 2, 3, 4, 5.</span>

<span style="color:green">**Numeric Answer**  </span>  
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
$SE(\hat{\beta_0}) =$   
$SE(\hat{\beta_1}) =$   
$SE(\hat{\beta_2}) =$   
$SE(\hat{\beta_3}) =$   
$SE(\hat{\beta_4}) =$   
$SE(\hat{\beta_5}) =$   


### <span style="color:DarkViolet">Question 24</span> **<span style="color:Crimson">(2 points)</span>**:

Bootstrap Statistics :
        original        bias     std. error
t1* 48.914178608 -13.961072182 130.03305599
t2* -8.228180223   2.653216677  20.77020206
t3* -0.616152497   0.173537338   1.80913201
t4*  0.103075071  -0.033028970   0.28116241
t5*  0.311160154  -0.128803517   0.81741639
t6* -0.001764375   0.001611177   0.01070411

<span style="color:DarkViolet">The standard errors estimated from usual linear regression methods are shown in the R output below:</span>

$\texttt{Coefficients:				}$

$\texttt{Variable       Estimate  Std. Error  t value	 PR(>|t|)}$

$\texttt{(Intercept)	 48.914179	90.852925	 0.538	   0.595}$

$\texttt{Girth	       -8.228180	13.803580	-0.596	   0.556}$

$\texttt{Height		     -0.616152	 1.250446	-0.493	   0.626}$

$\texttt{GirthHeight	  0.103075	 0.180291	 0.572	   0.573}$

$\texttt{Girth2	        0.311160	 0.536379	 0.580	   0.567}$

$\texttt{Girth2Height	 -0.001764	 0.006621	-0.266	   0.792}$

<span style="color:DarkViolet">How do these values compare to the standard errors computed in the previous set of questions? </span>

<span style="color:green">**Multiple Choice Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of 

A) 	The estimates from usual linear regression methods are **greater**.

	
->B)  The estimates from usual linear regression methods are **less**.

	
C) 	The two sets of estimates are about the **same**.


***

## Problem 2 - Model Selection

<span style="color:DarkViolet">This problem practices application of proper model selection techniques, with a multiple linear regression model.
We will continue working with the predictive model using multiple linear regression.  However, we will now consider selection between 6 possible models:</span>

<span style="color:DarkViolet">Model 1: 
$Volume = \beta_0+\beta_1\cdot Girth +\beta_2\cdot Height+\beta_3\cdot Girth\cdot Height+\beta_4 \cdot Girth^2+\beta_5\cdot Girth^2\cdot Height$  
</span>

<span style="color:DarkViolet">Model 2: 
$Volume = \beta_0+\beta_1\cdot Girth +\beta_2\cdot Height$  
</span>

<span style="color:DarkViolet">Model 3: 
$Volume = \beta_0+\beta_1\cdot Girth +\beta_2\cdot Height+\beta_3\cdot Girth\cdot Height$  
</span>

<span style="color:DarkViolet">Model 4: 
$Volume = \beta_0+\beta_1\cdot Girth +\beta_2\cdot Height+\beta_4 \cdot Girth^2+\beta_5\cdot Girth^2\cdot Height$  </span>

<span style="color:DarkViolet">Model 5: 
$Volume = \beta_0+\beta_4 \cdot Girth^2+\beta_5\cdot Girth^2\cdot Height$  
</span>

<span style="color:DarkViolet">Model 6: 
$Volume = \beta_0+\beta_5\cdot Girth^2\cdot Height$  
</span>

### <span style="color:DarkViolet">Questions 25-30</span> **<span style="color:Crimson">(6 points, 1 each)</span>**:

<span style="color:DarkViolet">Use LOOCV (note n = 31) method to calculate $CV_{(31)}$ for each of Models 1-6.  Report the $CV_{(31)}$ for each model.</span>

<span style="color:green">**Numeric Answer** </span>  
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  

#         

For Model 1, $CV_{(31)}$ = 8.957115  
For Model 2, $CV_{(31)}$ = 18.157829  
For Model 3, $CV_{(31)}$ = 7.904433  
For Model 4, $CV_{(31)}$ = 8.037109  
For Model 5, $CV_{(31)}$ = 7.075083 
For Model 6, $CV_{(31)}$ = 6.649682 
(use code space in next question)  

### <span style="color:DarkViolet">Question 31</span> **<span style="color:Crimson">(4 points)</span>**:

<span style="color:DarkViolet"> Enter your R code for computing the $CV_{(31)}$ measure for Model 6 below. </span>

<span style="color:green">**Possible Answer**: </span>
```{r echo=TRUE}

Model1=(Volume ~ Girth + Height + GirthHeight + Girth2 + Girth2Height)

Model2=(Volume ~ Girth + Height)

Model3=(Volume ~ Girth + Height + GirthHeight)

Model4=(Volume ~ Girth + Height + Girth2 + Girth2Height)

Model5=(Volume ~ Girth2 + Girth2Height)

Model6=(Volume ~ Girth2Height)

#Model4 = (BodyFatSiri ~ Abs+Weight+Wrist+Forearm)
allModels = list(Model1,Model2,Model3,Model4,Model5,Model6)	

#Q31

#Q25

#Q26

#Q27

#Q28

#Q29

#Q30

#applying 10-fold cross-validation for model selection
#k = 10 
#groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))  #produces list of group labels
#groups
#set.seed(2)
#cvgroups = sample(groups,n)  #orders randomly, with seed (2) to determine starting point

#allmodelMSE = rep(NA,6)  #place-holder for results
#allmodelMSEadj = rep(NA,6)  #place-holder for results
allmodelCV31 = rep(NA,6) #place-holder for results
	#fits for each model m, including predictors 1:m in order of forward step regression selection
for (m in 1:6) {
  
  #prediction via cross-validation
  allpredictedCV = rep(0,31)
  
  #####################################
  for (i in 1:31)  {
    lmfitCV = lm(formula = allModels[[m]],data=trees[-i,])
    allpredictedCV[i] = predict.lm(lmfitCV,trees[i,])
  }
  
 
  #####################################
  
  allmodelCV31[m] = sum((allpredictedCV-trees$Volume)^2)/31
}
allmodelCV31


```


### <span style="color:DarkViolet">Question 32</span> **<span style="color:Crimson">(1 point)</span>**:

<span style="color:DarkViolet">Which model would you select based on the values of $CV_{(31)}$ for LOOCV? </span>

<span style="color:green">**Multiple Choice Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
Model 1,  
Model 2,  
Model 3,  
Model 4,  
Model 5, or  
-> Model 6  

***


### <span style="color:DarkViolet">Question 33</span> **<span style="color:Crimson">(2 points)</span>**:

<span style="color:DarkViolet">Explain why you chose the model selected in the previous question. </span>

Model 6 has the lowest training error.

<span style="color:green">**Text Answer**: </span>

### <span style="color:DarkViolet">Questions 34-39</span> **<span style="color:Crimson">(6 points, 1 each)</span>**:

<span style="color:DarkViolet">Using the same split of the data into five sets as you performed in Problem 1, use 5-fold cross-validation method to calculate $CV_{(5)}$  for each of Models 1-6.  Report the $CV_{(5)}$  for each model.</span>

```{r}


#Q34

#Q35

#Q36

#Q37

#Q38

#Q39

k=5
groups = c(rep(1:k,6),1)
set.seed(2)
cvgroups = sample(groups,31)  #orders randomly, with seed (2) to determine starting point
# Questions 11-12
allmodelCV5 = rep(NA,6)



for (m in 1:6) {
  allpredictedCV = rep(0,31)
  for (i in 1:k)  {
    groupi = (cvgroups == i)
    lmfitCV = lm(formula = allModels[[m]],data=trees,subset=!groupi)
    allpredictedCV[groupi] = predict.lm(lmfitCV,trees[groupi,])
  }

  CV5 = sum((allpredictedCV-trees$Volume)^2)/31
  allmodelCV5[m] = sum((allpredictedCV-trees$Volume)^2)/31
}
allmodelCV5



```

<span style="color:green">**Numeric Answer** </span>  
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
For Model 1, $CV_{(5)}$ = 19.741684 
For Model 2, $CV_{(5)}$ = 19.973142 
For Model 3, $CV_{(5)}$ = 10.012937 
For Model 4, $CV_{(5)}$ = 13.323779 
For Model 5, $CV_{(5)}$ = 10.034371 
For Model 6, $CV_{(5)}$ = 9.243768 
(use code space above)  



### <span style="color:DarkViolet">Question 40</span> **<span style="color:Crimson">(1 point)</span>**:

<span style="color:DarkViolet">Which model would you select based on the values of $CV_{(5)}$ for 5-fold CV? </span>

<span style="color:green">**Multiple Choice Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
Model 1,  
Model 2,  
Model 3,  
Model 4,  
Model 5, or  
->Model 6  


### <span style="color:DarkViolet">Question 41</span> **<span style="color:Crimson">(2 points)</span>**:

<span style="color:DarkViolet">Explain why you chose the model selected in the previous question. </span>

<span style="color:green">**Text Answer**: </span>

Model 6 has the lowest error.

### <span style="color:DarkViolet">Question 42</span> **<span style="color:Crimson">(3 points)</span>**:

<span style="color:DarkViolet">Considering the form of the model that was selected by cross-validation, why does this model make sense from a practical standpoint? </span>


It is very easy to calculate.

<span style="color:green">**Text Answer**: </span>

*** 


## Problem 3 - Model Assessment & Selection with KNN

<span style="color:DarkViolet"> This problem practices application of proper model assessment and selection techniques, with the kNN model. </span> 

<span style="color:DarkViolet"> **Important**:  Use the FNN library for fitting K-nearest neighbors, to obtain consistent answers.</span>

<span style="color:DarkViolet"> In this problem, you will once again use the K-nearest neighbors approach to analyze the gas mileage of cars.  You will use the **Auto** data set from the ISLR package, along with the two new variables, **weight.std** and **year.std** (standardized values of the weight and year), that you created in Homework 1: K-Nearest Neighbors.</span>




### <span style="color:DarkViolet">Question 43</span> **<span style="color:Crimson">(3 points)</span>**:

<span style="color:DarkViolet"> **Model assessment**   </span>
<span style="color:DarkViolet"> Starting with: </span>

$\texttt{groups = c(rep(1:10,39),1,2)}$

<span style="color:DarkViolet"> Set R’s seed to 2 and use sample() to divide the data into ten sets.  Then use 10-fold cross-validation method to calculate $CV_{(10)}$  for 1-nearest neighbor regression. Remember to re-standardize each training set inside the cross-validation. Report the value.   </span>

<span style="color:green">**Numeric Answer** </span>  
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
<span style="color:DarkViolet"> $CV_{(10)}$ = </span>  
(use code space in next question)  


### <span style="color:DarkViolet">Question 44</span> **<span style="color:Crimson">(4 points)</span>**:

<span style="color:DarkViolet">Enter your R code for computing the $CV_{(10)}$ measure below. </span>

<span style="color:green">**Code Answer**: </span>
```{r echo=TRUE}
library(ISLR)
library(FNN)

data("Auto")
set.seed(2)

num_examples = dim(Auto)[1] #get the number of rows

k = 10 #using 10-fold cross-validation
groups = c(rep(1:k,floor(num_examples/k)),1:(num_examples-floor(num_examples/k)*k))  #produces list of group labels
#groups
cvgroups = sample(groups,num_examples)  #orders randomly, with seed (2) to determine starting point
#prediction via cross-validation
allpredictedCV = rep(0,num_examples)

for (i in 1:k)  {
  groupi = (cvgroups == i)
  
  train.x = Auto[!groupi,c("weight","year")]
  train.y = Auto[!groupi,"mpg"]
  valid.x = Auto[groupi,c("weight","year")]
  
  train.x.std = scale(train.x)
  attr(train.x.std, "scaled:center")
  attr(train.x.std, "scaled:scale")
  
  #standardize validation set with mean and standard deviation of the training set
  valid.x.std = scale(valid.x, center = attr(train.x.std, "scaled:center"), scale = attr(train.x.std, "scaled:scale"))
  
  #do the analysis
  predictions = knn.reg(train.x.std, valid.x.std, train.y, k=1)
  #print(class(predictions$pred))
  #print(predictions$pred)
  #print(length(predictions$pred))
  #print(length(Boston[groupi,"crim"]))
  #allpredictedCV[i] = ((Boston[groupi,"crim"]-predictions$pred)^2)/length(predictions$pred)
  #allpredictedCV[i] = mean((Boston[groupi,"crim"]-predictions$pred)^2)
  allpredictedCV[groupi] = predictions$pred
}

#mean(allpredictedCV)
mean( (Auto[,"mpg"] - allpredictedCV)^2 )
```



### <span style="color:DarkViolet">Question 45</span> **<span style="color:Crimson">(1 point)</span>**:

<span style="color:DarkViolet">In general, how should the $CV_{(10)}$ value compare to the value of MSE (computed by reusing the same data used to fit the model)?</span>

<span style="color:green">**Multiple Choice Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of 
-> $CV_{(10)} > MSE$,  
$CV_{(10)} < MSE$, or  
$CV_{(10)} \approx MSE$

***

### <span style="color:DarkViolet">Question 46</span> **<span style="color:Crimson">(3 points)</span>**:

<span style="color:DarkViolet">Consider models 1-30 as the k-nearest neighbors regression for values of k from 1 to 30. Using the same split of the data into ten sets as you performed in the Model assessment section, use 10-fold cross-validation method to calculate CV(10) for each of Models 1-30; remember to re-standardize each training set inside the cross-validation. Make a plot of the CV(10) as a function of k.
Upload your plot to Homework 2: CV(10) Plot.  </span>

<span style="color:green">**Plot Answer - submit to D2L discussion board *Homework 2: CV(10) Plot* **: </span>
```{r echo=FALSE}
num_groups = 10
cv10Byk = rep(NA,30)

for(k in 1:30) {
  allpredictedCV = rep(0,num_examples)
  for (i in 1:num_groups)  {
    groupi = (cvgroups == i)
  
    train.x = Auto[!groupi,c("weight","year")]
    train.y = Auto[!groupi,"mpg"]
    valid.x = Auto[groupi,c("weight","year")]
  
    train.x.std = scale(train.x)
    attr(train.x.std, "scaled:center")
    attr(train.x.std, "scaled:scale")
  
  #standardize validation set with mean and standard deviation of the training set
    valid.x.std = scale(valid.x, center = attr(train.x.std, "scaled:center"), scale = attr(train.x.std, "scaled:scale"))
  
  #do the analysis
    predictions = knn.reg(train.x.std, valid.x.std, train.y, k=k)
  #print(class(predictions$pred))
  #print(predictions$pred)
  #print(length(predictions$pred))
  #print(length(Boston[groupi,"crim"]))
  #allpredictedCV[i] = ((Boston[groupi,"crim"]-predictions$pred)^2)/length(predictions$pred)
  #allpredictedCV[i] = mean((Boston[groupi,"crim"]-predictions$pred)^2)
    allpredictedCV[groupi] = predictions$pred
  }

  #mean(allpredictedCV)
  cv10Byk[k] = mean( (Auto[,"mpg"] - allpredictedCV)^2 )
}
cv10Byk

plot(cv10Byk~seq(1, 30),xlab="k",ylab="CV10")
```



### <span style="color:DarkViolet">Question 47</span> **<span style="color:Crimson">(2 points)</span>**:

<span style="color:DarkViolet">Which k (number of nearest neighbors) would you select based on the values of $CV_{(10)}$ for 10-fold CV?
k=19 looks like it has the least error.

 </span>

<span style="color:green">**Numeric (Integer) Answer** </span>  
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  


### <span style="color:DarkViolet">Question 48 </span> **<span style="color:Crimson">(1 point)</span>**:

<span style="color:DarkViolet">Explain why you chose the k value specified in the previous question. *Comment on both model predictive ability and model complexity.*</span>

k =20 has the minimum error, but it is better to have a k that is odd in case of ties, so k=19 was selected. Based on the error rate, k=19 is close to the minimum error rate, and so has good predictive ability. It is also large enough that the model will not over fit, and thus make it easier to interpret boundaries between points. There is also a rule of thumb for selecting k that is the square root of the number of examples. Here this is the square root 392, which happens to equal 19.8. Rounding down gives us 19.

<span style="color:green">**Text Answer**: </span>



### <span style="color:DarkViolet">Question 49</span> **<span style="color:Crimson">(1 point)</span>**:

<span style="color:DarkViolet">How does your selected model's k (number of nearest neighbors) compare to the one you chose in Homework 1? </span>

<span style="color:green">**Multiple Choice Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of 
	
k is **greater** than in Homework 1, or

	
k is **less** than in Homework 1.












