---
title: "Homework 3 R markdown"
author: "(your name here)"
date: '`r Sys.Date()`'
output:
  word_document:
    fig_height: 4
    fig_width: 4.5
  pdf_document:
    fig_height: 4
    fig_width: 4.5
  html_document:
    fig_height: 4
    fig_width: 4.5
---


```{r, setup, include=FALSE}
require(mosaic)   # Load additional packages here 

# Some customization.  You can alter or delete as desired (if you know what you are doing).
trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

#### <span style="color:Blue">**Intellectual Property:**</span>  
These problems are the intellectual property of the instructors and may not be reproduced outside of this course.

#### <span style="color:Crimson">**Due Date:**</span>  


***  

#####################################################
## <span style="color:DarkViolet">Problem 1:  Linear Regression  </span>
#####################################################

<span style="color:DarkViolet">In this problem, you will use multiple linear regression to model the incomes of people from Wisconsin.</span>

<span style="color:DarkViolet">Data file (on D2L): *Wisconsin_income.csv*  </span>

<span style="color:DarkViolet">Data dictionary (on D2L): *Wisconsin_income data dictionary.txt*</span>

<span style="color:DarkViolet">Public Use Microdata from American Community Survey.  Accessed from http://www2.census.gov/programs-surveys/acs/data/pums/2014/1-Year/ on 27 July 2016.</span>
 

```{r echo=FALSE}

```

<span style="color:DarkViolet"></span>


### <span style="color:DarkViolet">Question 1</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Read in the data Wisconsin_income.csv.  Open the data dictionary in a text editor.  

<span style="color:DarkViolet">Notice that the following 9 variables are categorical, but are coded as numbers:  </span>  

* Citizenship  
* Class of worker  
* Language spoken at home  
* Marital status  
* Sex  
* Disability  
* Race  
* Hispanic  

<span style="color:DarkViolet">Tell R to treat them as factors.  Enter your R code below.</span>


<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
wisc=read.csv("Wisconsin_income.csv")
wisc$CIT2 = as.factor(wisc$CIT2)
wisc$COW = as.factor(wisc$COW)
wisc$LANX = as.factor(wisc$LANX)
wisc$MAR = as.factor(wisc$MAR)
wisc$SEX = as.factor(wisc$SEX)
wisc$DIS = as.factor(wisc$DIS)
wisc$RAC = as.factor(wisc$RAC)
wisc$Hispanic = as.factor(wisc$Hispanic)
```

### <span style="color:DarkViolet">Question 2</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Make histograms of people’s total earnings, usual hours worked per week, and travel time to work.  Which of these 3 variables are likely to benefit from log-transformation?  Apply the transformation if appropriate, and enter your R code below.</span>


<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
hist(wisc$PERNP)
hist(wisc$WKHP)
hist(wisc$JWMNP)
#total earnings and travel time to work appear to be right skewed
wisc$PERNP = log(wisc$PERNP)
wisc$JWMNP = log(wisc$JWMNP)
```

### <span style="color:DarkViolet">Question 3</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Use *regsubsets()* to perform best subset selection for a linear model for total earnings as a function of all other variables in the data set.  
If you log-transformed any variables in the previous question, use the **transformed** variables, <span style="color:red"> *not* </span> the original variables, here.  Consider models with up to 41 variables.  Make a plot summarizing which variables are included in the best model of each size.  Enter your R code below.</span>


<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
library(leaps)
regfit = regsubsets(PERNP~.,data=wisc,method="seqrep",nvmax=41)
plot(regfit)
regfit.summary = summary(regfit)
#regfit.summary$adjr2
plot(regfit.summary$bic, xlab="Number of Variables", ylab = "BIC", type="l", lwd=2)
which.min(regfit.summary$bic)
```

***

### <span style="color:DarkViolet">Question 4</span> **<span style="color:Crimson">(3 points)</span>**
<span style="color:DarkViolet">Plot adjusted $R^2$ as a function of number of variables.  Find the number of variables in the best model, as measured by adjusted $R^2$.  Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 4
#plot(regfit.full,scale="adjr2")
plot(regfit.summary$adjr2, xlab="Number of Variables", ylab = "adjr2", type="l", lwd=2)
which.max(regfit.summary$adjr2)
```

### <span style="color:DarkViolet">Question 5</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">How many variables (not counting the intercept) are in the best model, as measured by adjusted $R^2$?</span>

36 variables  

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**: 

### <span style="color:DarkViolet">Question 6</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">How many variables (not counting the intercept) are in the best model, as measured by BIC?</span>
19 variables

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**: 

***

### <span style="color:DarkViolet">Question 7</span> **<span style="color:Crimson">(4 points)</span>**
<span style="color:DarkViolet">Set the random seed equal to 3.  Perform 10-fold cross-validation to choose the best size of model (from 1 to 41 variables) based on cross-validation MSE.  Record the mean squared error within each fold for each size of variable.  **Note**: This step will probably take a few minutes to run!  
Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 7

# Question 8

#define a predict() function for regsubset objects, try not running and see if predict function below works
predict.regsubsets <- function(object, newdata, id, ...) {
    form = as.formula(object$call[[2]])
    mat = model.matrix(form, newdata)
    coefi = coef(object, id=id)
    xvars = names(coefi)
    mat[,xvars] %*% coefi
} #end function predict.regsubsets

#cross validation of logistic regression
n = dim(wisc)[1] #number of observations
library(leaps)
#n=42
k = 10 #10 fold cross validation
groups = c(rep(1:k,floor(n/k)), 1:(n-floor(n/k)*k))

set.seed(3) # ensures replicable results
cvgroups = sample(groups, n) #places observations in random groups
group.error = matrix(,nr=41, nc=k) #row = number of variables, column = which fold

for(i in 1:k) {
  groupi = (cvgroups == i) #all observations in group i
  
  cv.fit = regsubsets(PERNP~.,data=wisc[!groupi,],method="seqrep",nvmax=41)
  
  for(j in 1:41) {
    y.pred = predict(cv.fit, newdata = wisc[groupi,], id=j)
    group.error[j,i] = mean((wisc$PERNP[groupi] - y.pred)^2) 
  } #end iter over model size
} #end iter over folds

MSE = apply(group.error, 1, mean)
plot(MSE)
which.min(MSE)

```
number of variables == 39  gives lowest MSE
### <span style="color:DarkViolet">Question 8</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">Find the mean of the MSEs from all the folds with the same number of variables.  Which number of variables gives the lowest cross-validation MSE?</span>

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**: 

### <span style="color:DarkViolet">Question 9</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Estimate the standard error of the cross-validation errors and find the most parsimonious model with a CV error within 1 standard error of the lowest.  
Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 9

#find models within one standard deviation of best model. pick simplest one.
se = apply(group.error,1,sd)/sqrt(k)
se[39]
which(MSE <= MSE[39] + se[39])
#based on one standard error rule choose 6, most parsimonious,
coef(regfit,6)

#find factors
summary(wisc)
levels(wisc$COW)
levels(wisc$MAR)
```

***

### <span style="color:DarkViolet">Question 10</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">How many variables (not counting the intercept) are in the most parsimonious model with a CV error within 1 standard error of the lowest?</span>
6 variables is the most parsimonious model with a CV error within 1 standard error of the lowest.
<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**: 

### <span style="color:DarkViolet">Question 11</span> **<span style="color:Crimson">(4 points)</span>**
<span style="color:DarkViolet">Use $\texttt{regsubsets}$ to find the best model for the whole data set which has the number of variables you found in the previous question.  Write 4-6 sentences interpreting the signs of the coefficients.  Include possible explanations for the associations.  **Note**: It may be helpful to refer to the data dictionary and/or a map of Wisconsin, such as https://en.wikipedia.org/wiki/Wisconsin#/media/File:Wisconsin-counties-map.gif.  Refer to variables in plain English. </span>

LOG_PERNP   (Intercept)        COW6        MAR5        SEX2        WKHP   Education 
              8.19757196 -0.63769603 -0.24779279 -0.28139377  0.02987906  0.09413591 

Total person's earnings (PERNP) has been log transformed, so to get the real effect of each variable in dollars both sides need to be exponentiated. The sign on education is positive, so each additional year of education has a positive effect on total earnings. The sign on sex(SEX2) is negative. Male is coded as 1 and female is coded as 2, which would mean that being female has more of a negative effect on total person's earning than being male. Usual hours worked(WHKP) is positive, which makes sense. The more hours you work the more your total earnings. Marital status(MAR5) is negative. Married is coded as 1 the lowest value, so married people tend to make more than non married people. Class of worker is also negative with the lowest value of 1 indicating the person works in the private for profit sector. Workers in the private sector tend to make more than state, federal and non profit employees.


PERNP(Total person's earnings) = COW6(Class of worker) + MAR5(Marital status) + SEX2(Sex) + WKHP(Usual hours worked per week past 12 months) + Education(Years of education, not counting kindergarten.)
<span style="color:green">**Text Answer**: </span>
.  
.  
.  
.  
.  

***



#####################################################
## <span style="color:DarkViolet">Problem 2:  Logistic Regression  </span>
#####################################################

<span style="color:DarkViolet">In this problem, you will use logistic regression to predict whether a car has low or high gas mileage.</span>

### <span style="color:DarkViolet">Question 12</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Write R code to:  </span>

* Load the **Auto** data set into R.  The data set is in the ISLR library.  
* Create a binary variable that equals 1 for cars with gas mileage above the median and a 0 for cars with gas mileage below the median.  Tell R to treat it as a factor.  
* Tell R to treat the origin variable as a factor.  

<span style="color:DarkViolet">Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 12
library(ISLR)
data("Auto")
Auto$mpg.bin = as.factor(ifelse(Auto$mpg >median(Auto$mpg), 1, 0))
Auto$origin = as.factor(Auto$origin)

pairs(Auto)
```

### <span style="color:DarkViolet">Question 13</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Make a matrix of scatterplots of the variables in **Auto**.  Do you have any concerns about collinearity?  If so, for which variables?  Explain.</span>

<span style="color:green">**Text Answer**: </span>
Combinations of the variables displacement, horsepower, weight and acceleration all appear to have a strong linear relationship with each other.

***

### <span style="color:DarkViolet">Question 14</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Perform logistic regression of mpg.bin on the other variables in **Auto** (excluding mpg and name).  Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 14
fit = glm(mpg.bin ~ .-mpg-name, data=Auto, family = "binomial")
#summary(fit)
# Question 15
#install.packages("car")
library(car)
vif(fit)
```


### <span style="color:DarkViolet">Question 15</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">Compute the variance inflation factor for each of the predictor variables in the model.  Which variable(s) have VIFs greater than or equal to 10?</span>

The variable displacement has a VIF greater than 10.

<span style="color:green">**Multiple SELECT Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
cylinders,  

	
->displacement,  

	
horsepower, and/or

	
weight

### <span style="color:DarkViolet">Question 16</span> **<span style="color:Crimson">(4 points)</span>**
<span style="color:DarkViolet">Remove any variables with VIFs greater than or equal to 10.  Set the random seed equal to 3 and perform 10-fold cross-validation.  In each phase of the cross-validation, fit the logistic model (excluding name, continuous mpg, and the variable(s) you found in the previous question and predict the probability of high gas mileage for each data point in the validation set.  Store all of the probabilities in a single vector.  
**Note**:  Depending on how you set up the formula in the logistic regression, the predict function may give an error, “Factor name has new levels.”  This is complaining about the fact that there are models of car in the validation set that weren’t included in the training data.  But, it’s not really a problem, because we’re not using name as a predictor variable.  You can create a new data frame that excludes name, or you can update the levels of the name factor in the logistic model, as shown here: http://stackoverflow.com/questions/22315394/factor-has-new-levels-error-for-variable-im-not-using  
Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 16
#cross validation of logistic regression
n = dim(Auto)[1] #number of observations
k = 10 #10 fold cross validation
groups = c(rep(1:k,floor(n/k)), 1:(n-floor(n/k)*k))
set.seed(3) # ensures replicable results
cvgroups = sample(groups, n) #places observations in random groups
predictvals = rep(-1,n) #makes trouble shooting easier
Auto$name <- NULL # remove name column
for(i in 1:k) {
  groupi = (cvgroups == i) #all observations in group i
  fit = glm(mpg.bin ~ .-mpg-displacement, data=Auto[!groupi,], family = "binomial")
  predictvals[groupi] = predict(fit, Auto[groupi,], type = "response") #response indicates to give predicted probability vs logit or log odds
  
}
```


***

### <span style="color:DarkViolet">Question 17</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Create a ROC curve for this model.  What is its AUC?</span>

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**:  

```{r}
#Question 17
#install.packages("pROC")
library(pROC)
myroc = roc(response=Auto$mpg.bin, predictor = predictvals)
plot.roc(myroc)
myroc$auc
```

Area under the curve: 0.9693

### <span style="color:DarkViolet">Question 18</span> **<span style="color:Crimson">(3 points)</span>**
<span style="color:DarkViolet">Upload an image of your ROC curve to *Homework 3: ROC Curve* (discussion board on D2L).  As part of your discussion post, write 1-2 sentences assessing the model based on the ROC curve and AUC.</span>

<span style="color:green">**Text Answer**: </span>

<span style="color:green">**Graph Answer**  </span>: 
```{r}
# Question 18

```



